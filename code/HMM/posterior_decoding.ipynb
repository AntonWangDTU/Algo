{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zbEloWy0zgFn"
   },
   "source": [
    "# Posterior Decoding\n",
    "Implementation of the Posterior Decoding algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yoG3k9pCzk3c"
   },
   "source": [
    "## Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jk4CMIT5zSrp"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode sequence as integers (index values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode( sequence, symbols):\n",
    "    \n",
    "    enc = [0] * len(sequence)\n",
    "    \n",
    "    for i in range(len(sequence)):\n",
    "        enc[i] = symbols.find(sequence[i])\n",
    "    \n",
    "    return(enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4zmxoNo0zve9"
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pmvxr0uUk_sd"
   },
   "outputs": [],
   "source": [
    "states = 2\n",
    "\n",
    "symbols = \"123456\"\n",
    "\n",
    "#input_sequence = \"566611234\"\n",
    "#input_sequence = \"31245366664\"\n",
    "input_sequence = \"34512331245366664666563266\"\n",
    "\n",
    "input_encode = encode( input_sequence, symbols)\n",
    "\n",
    "initial_prob = [1.0/states, 1.0/states]\n",
    "\n",
    "transition_matrix = np.asarray([0.95, 0.05, 0.1, 0.9]).reshape(2,2)\n",
    "\n",
    "fair_prob = [1.0/6, 1./6, 1./6, 1./6, 1./6, 1./6]\n",
    "loaded_prob = [1./10, 1./10, 1./10, 1./10, 1./10, 5./10] \n",
    "emission_probs = [fair_prob, loaded_prob]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_qWOQUfGkJOI"
   },
   "source": [
    "## Forward Loop\n",
    "### Remember that we here do NOT work in log space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fyHv6-vuzxt2"
   },
   "outputs": [],
   "source": [
    "def initialize_forward(input_encode, states, initial_prob, emission_probs):\n",
    "    \n",
    "    alpha = np.zeros(shape=(states, len(input_encode)))\n",
    "        \n",
    "    for i in range(0, states): \n",
    "        \n",
    "        alpha[i][0] = initial_prob[i]*emission_probs[i][input_encode[0]]\n",
    "        \n",
    "    return alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "2A6Rx7sukIjM",
    "outputId": "cc4ed1b3-aa15-4276-f114-eb6a3e26785e"
   },
   "outputs": [],
   "source": [
    "alpha = initialize_forward(input_encode, states, initial_prob, emission_probs)\n",
    "\n",
    "# main loop\n",
    "for i in range(1, len(input_encode)):\n",
    "    \n",
    "    for j in range(0, states):\n",
    "\n",
    "        _sum = 0\n",
    "        \n",
    "        for k in range(0, states):\n",
    "            \n",
    "            _sum += alpha[k][i-1]*transition_matrix[k][j]   #XX           \n",
    "         \n",
    "        # store prob\n",
    "        alpha[j][i] = emission_probs[j][input_encode[i]] * _sum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R8IztniOkK8Q"
   },
   "source": [
    "## Backward Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TngUQKM2kTY_"
   },
   "outputs": [],
   "source": [
    "def initialize_backward(input_encode, states):\n",
    "    \n",
    "    #beta = np.zeros(shape=(states, len(input_encode), dtype=float))\n",
    "    beta = np.zeros(shape=(states, len(input_encode)))\n",
    "        \n",
    "    for i in range(0, states):\n",
    "  \n",
    "        beta[i][-1] = 1\n",
    "        \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "SasPJXJYnhM1",
    "outputId": "b968d3fc-b7fb-4be0-e5d0-b85661bff52a"
   },
   "outputs": [],
   "source": [
    "beta = initialize_backward(input_encode, states)\n",
    "\n",
    "# main loop\n",
    "for i in range(len(input_encode)-2, -1, -1):\n",
    "    \n",
    "    for j in range(0, states):\n",
    "\n",
    "        _sum = 0\n",
    "\n",
    "        for k in range(0, states):\n",
    "            \n",
    "            _sum +=  transition_matrix[j][k] * beta[k][i+1] * emission_probs[k][input_encode[i+1]] #\n",
    "        \n",
    "         #store prob\n",
    "        beta[j][i] = _sum  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bzEzXRSX0A79"
   },
   "source": [
    "## Posterior Loop\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "M5o3yT_vzSry",
    "outputId": "e8adbd06-fb24-4be8-9dfe-4d0df12b327a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log(Px): -41.70474157060052\n",
      "Posterior 0 3 2 -2.4849066497880004 -39.35940929634274 0.8697283342927764\n",
      "Posterior 1 4 3 -4.266715788162887 -37.52445740365702 0.917198263539344\n",
      "Posterior 2 5 4 -6.073538637630933 -35.68995230080138 0.9429430714098719\n",
      "Posterior 3 1 0 -7.893430617460898 -33.85625161703387 0.9560542086837365\n",
      "Posterior 4 2 1 -9.720352401473978 -32.0240017844215 0.9611617063864735\n",
      "Posterior 5 3 2 -11.551114466753617 -30.19437700488653 0.9600692122362451\n",
      "Posterior 6 3 2 -13.383992144478592 -28.369529118205953 0.9523909258478439\n",
      "Posterior 7 1 0 -15.218040712005948 -26.55346547351473 0.9354153582437182\n",
      "Posterior 8 2 1 -17.052738967590443 -24.753871660818092 0.903147804079745\n",
      "Posterior 9 4 3 -18.887798224281546 -22.986317024421123 0.844193387856058\n",
      "Posterior 10 5 4 -20.723058230083396 -21.28585650141364 0.7377331088630769\n",
      "Posterior 11 3 2 -22.55842991926611 -19.75113321212816 0.5461718764211234\n",
      "Posterior 12 6 5 -24.393863756721874 -18.911047396484218 0.20186228276000984\n",
      "Posterior 13 6 5 -26.199557289289125 -17.997150930944333 0.0827470719506699\n",
      "Posterior 14 6 5 -27.9290751547782 -16.922954392648915 0.04296850056088228\n",
      "Posterior 15 6 5 -29.49459377766798 -15.596930035614456 0.033817317937858055\n",
      "Posterior 16 4 3 -30.806208273579358 -14.020105220818133 0.044087811242227375\n",
      "Posterior 17 6 5 -32.437153981430065 -12.940419463861659 0.025404425834313484\n",
      "Posterior 18 6 5 -33.83768189722398 -11.60741019223766 0.023745778329213693\n",
      "Posterior 19 6 5 -34.974188214766386 -10.02520827852529 0.037080838595683244\n",
      "Posterior 20 5 4 -35.92190166930413 -8.287069824818245 0.08173851866589908\n",
      "Posterior 21 6 5 -37.47408010274853 -6.654569702870829 0.08857476910403222\n",
      "Posterior 22 3 2 -38.76915848573153 -4.891710934689039 0.14140490322893587\n",
      "Posterior 23 2 1 -40.39570778625175 -3.2016636959870794 0.1506750253095928\n",
      "Posterior 24 6 5 -42.13140352817434 -1.6964492894237302 0.11965876081017232\n",
      "Posterior 25 6 5 -43.70883510764154 0.0 0.1347824156058245\n"
     ]
    }
   ],
   "source": [
    "# posterior = f * b / p_x\n",
    "\n",
    "posterior = np.zeros(shape=(len(input_encode)), dtype=float)\n",
    "\n",
    "p_state = 0\n",
    "\n",
    "p_x = 0\n",
    "for j in range(0, states):\n",
    "    p_x += alpha[j][-1]\n",
    "\n",
    "print (\"Log(Px):\", np.log(p_x))\n",
    "\n",
    "for i in range(0, len(input_encode)):\n",
    "        \n",
    "    posterior[i] = (alpha[p_state][i]*beta[p_state][i])/p_x # p = (f_i * b_i)/p_x\n",
    "\n",
    "    print (\"Posterior\", i, input_sequence[i], input_encode[i], np.log(alpha[p_state, i]), np.log(beta[p_state, i]), posterior[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "posterior_decoding.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
